{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport spacy\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom textblob import TextBlob\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\npd.options.mode.chained_assignment = None\nfrom nltk.corpus import wordnet\nimport os\nimport shutil\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom gensim.models import Word2Vec, FastText\nfrom gensim.models import KeyedVectors\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom tqdm import tqdm ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-06T11:11:06.337063Z","iopub.execute_input":"2025-09-06T11:11:06.337357Z","iopub.status.idle":"2025-09-06T11:11:06.346382Z","shell.execute_reply.started":"2025-09-06T11:11:06.337336Z","shell.execute_reply":"2025-09-06T11:11:06.345290Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"!pip install gensim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T11:11:16.167012Z","iopub.execute_input":"2025-09-06T11:11:16.167673Z","iopub.status.idle":"2025-09-06T11:11:20.245814Z","shell.execute_reply.started":"2025-09-06T11:11:16.167626Z","shell.execute_reply":"2025-09-06T11:11:20.244394Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\nRequirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\nRequirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\nRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.18.5->gensim) (2.4.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.18.5->gensim) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.18.5->gensim) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.18.5->gensim) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.18.5->gensim) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.18.5->gensim) (2024.2.0)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"google_model = api.load(\"word2vec-google-news-300\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T11:11:25.580418Z","iopub.execute_input":"2025-09-06T11:11:25.580782Z","iopub.status.idle":"2025-09-06T11:12:21.027632Z","shell.execute_reply.started":"2025-09-06T11:11:25.580753Z","shell.execute_reply":"2025-09-06T11:12:21.026444Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv',encoding=\"ISO-8859-1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T10:48:16.270510Z","iopub.execute_input":"2025-09-06T10:48:16.270863Z","iopub.status.idle":"2025-09-06T10:48:16.993667Z","shell.execute_reply.started":"2025-09-06T10:48:16.270837Z","shell.execute_reply":"2025-09-06T10:48:16.992581Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def preprocess_text(text):\n    if not isinstance(text, str):\n        text = str(text)\n        \n    text = text.lower()\n    \n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = re.sub(r'\\d+', '', text)\n\n    text = text.replace(\"br\", \"\").replace(\"<\", \"\").replace(\">\", \"\")\n\n    tokens = word_tokenize(text)\n    \n    stop_words = set(stopwords.words('english'))\n    tokens = [token for token in tokens if token not in stop_words]\n    \n    lemmatizer = WordNetLemmatizer()\n    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n    \n    return ' '.join(tokens)\n\ndf['processed_text'] = df['review'].apply(preprocess_text)\n\nprint(\"Original vs Preprocessed Text:\")\nfor i in range(3):\n    print(f\"\\nOriginal: {df['review'].iloc[i][:100]}...\")\n    print(f\"Processed: {df['processed_text'].iloc[i][:100]}...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T10:48:22.854975Z","iopub.execute_input":"2025-09-06T10:48:22.855347Z","iopub.status.idle":"2025-09-06T10:49:38.435098Z","shell.execute_reply.started":"2025-09-06T10:48:22.855316Z","shell.execute_reply":"2025-09-06T10:49:38.434185Z"}},"outputs":[{"name":"stdout","text":"Original vs Preprocessed Text:\n\nOriginal: One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. The...\nProcessed: one reviewer mentioned watching oz episode youll hooked right exactly happened first thing struck oz...\n\nOriginal: A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-B...\nProcessed: wonderful little production filming technique unassuming oldtimebbc fashion give comforting sometime...\n\nOriginal: I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air con...\nProcessed: thought wonderful way spend time hot summer weekend sitting air conditioned theater watching lighthe...\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"X = df['processed_text']\ny = df['sentiment']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\nprint(f\"\\nData split into training ({len(X_train)} samples) and testing ({len(X_test)} samples).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T10:49:54.818539Z","iopub.execute_input":"2025-09-06T10:49:54.818897Z","iopub.status.idle":"2025-09-06T10:49:55.229465Z","shell.execute_reply.started":"2025-09-06T10:49:54.818873Z","shell.execute_reply":"2025-09-06T10:49:55.228466Z"}},"outputs":[{"name":"stdout","text":"\nData split into training (40000 samples) and testing (10000 samples).\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def get_average_word_vector(tokens, wv_model, vector_size=100):\n    if hasattr(wv_model, 'wv'):\n        vectors = [wv_model.wv[word] for word in tokens if word in wv_model.wv]\n    else:\n        vectors = [wv_model[word] for word in tokens if word in wv_model]\n    \n    return np.mean(vectors, axis=0) if vectors else np.zeros(vector_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T10:51:25.846882Z","iopub.execute_input":"2025-09-06T10:51:25.847197Z","iopub.status.idle":"2025-09-06T10:51:25.853330Z","shell.execute_reply.started":"2025-09-06T10:51:25.847175Z","shell.execute_reply":"2025-09-06T10:51:25.852317Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"df['average_word_vector_google'] = df['processed_text'].apply(lambda x: get_average_word_vector(x.split(), google_model, 300))\n\nX = df['average_word_vector_google'].dropna().tolist()\ny = df['sentiment'].dropna().tolist()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\ngoogle_classifier = LogisticRegression()\ngoogle_classifier.fit(X_train, y_train)\n\ngoogle_y_pred = google_classifier.predict(X_test)\n\ngoogle_accuracy = accuracy_score(y_test, google_y_pred)\nprint(f\"Google News Accuracy: {google_accuracy:.4f}\")\nprint(\"Classification Report:\")\nprint(classification_report(y_test, google_y_pred))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, google_y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T11:15:42.045150Z","iopub.execute_input":"2025-09-06T11:15:42.045592Z","iopub.status.idle":"2025-09-06T11:16:02.758450Z","shell.execute_reply.started":"2025-09-06T11:15:42.045566Z","shell.execute_reply":"2025-09-06T11:16:02.757369Z"}},"outputs":[{"name":"stdout","text":"Google News Accuracy: 0.8504\nClassification Report:\n              precision    recall  f1-score   support\n\n    negative       0.85      0.85      0.85      4961\n    positive       0.85      0.85      0.85      5039\n\n    accuracy                           0.85     10000\n   macro avg       0.85      0.85      0.85     10000\nweighted avg       0.85      0.85      0.85     10000\n\nConfusion Matrix:\n[[4211  750]\n [ 746 4293]]\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from gensim.models import Word2Vec\nfrom gensim.models import FastText\n\nsent = df['processed_text'].apply(lambda x: x.split())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T11:20:32.244405Z","iopub.execute_input":"2025-09-06T11:20:32.245604Z","iopub.status.idle":"2025-09-06T11:20:35.607960Z","shell.execute_reply.started":"2025-09-06T11:20:32.245532Z","shell.execute_reply":"2025-09-06T11:20:35.607035Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"sg_model = Word2Vec(sentences=sent, vector_size=100, window=3, min_count=1, sg=1, workers=4)\n\ndf['average_word_vector_sg'] = df['processed_text'].apply(lambda x: get_average_word_vector(x.split(), sg_model))\n\nX = df['average_word_vector_sg'].dropna().tolist()\ny = df['sentiment'].dropna().tolist()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nsg_classifier = LogisticRegression()\nsg_classifier.fit(X_train, y_train)\n\nsg_y_pred = sg_classifier.predict(X_test)\n\nsg_accuracy = accuracy_score(y_test, sg_y_pred)\nprint(f\"SG Accuracy: {sg_accuracy:.4f}\")\nprint(\"Classification Report:\")\nprint(classification_report(y_test, sg_y_pred))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, sg_y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T11:20:55.705998Z","iopub.execute_input":"2025-09-06T11:20:55.706331Z","iopub.status.idle":"2025-09-06T11:22:44.727346Z","shell.execute_reply.started":"2025-09-06T11:20:55.706297Z","shell.execute_reply":"2025-09-06T11:22:44.726111Z"}},"outputs":[{"name":"stdout","text":"SG Accuracy: 0.8675\nClassification Report:\n              precision    recall  f1-score   support\n\n    negative       0.87      0.86      0.87      4961\n    positive       0.87      0.87      0.87      5039\n\n    accuracy                           0.87     10000\n   macro avg       0.87      0.87      0.87     10000\nweighted avg       0.87      0.87      0.87     10000\n\nConfusion Matrix:\n[[4279  682]\n [ 643 4396]]\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"cbow_model = Word2Vec(sentences=sent, vector_size=100, window=3, min_count=1, sg=0, workers=4)\n\ndf['average_word_vector_cbow'] = df['processed_text'].apply(lambda x: get_average_word_vector(x.split(), cbow_model))\n\nX = df['average_word_vector_cbow'].dropna().tolist()\ny = df['sentiment'].dropna().tolist()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\ncbow_classifier = LogisticRegression()\ncbow_classifier.fit(X_train, y_train)\n\ncbow_y_pred = cbow_classifier.predict(X_test)\n\ncbow_accuracy = accuracy_score(y_test, cbow_y_pred)\nprint(f\"CBOW Accuracy: {cbow_accuracy:.4f}\")\nprint(\"Classification Report:\")\nprint(classification_report(y_test, cbow_y_pred))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, cbow_y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T11:23:32.496445Z","iopub.execute_input":"2025-09-06T11:23:32.496828Z","iopub.status.idle":"2025-09-06T11:24:24.068090Z","shell.execute_reply.started":"2025-09-06T11:23:32.496802Z","shell.execute_reply":"2025-09-06T11:24:24.066909Z"}},"outputs":[{"name":"stdout","text":"CBOW Accuracy: 0.8531\nClassification Report:\n              precision    recall  f1-score   support\n\n    negative       0.86      0.84      0.85      4961\n    positive       0.85      0.86      0.86      5039\n\n    accuracy                           0.85     10000\n   macro avg       0.85      0.85      0.85     10000\nweighted avg       0.85      0.85      0.85     10000\n\nConfusion Matrix:\n[[4182  779]\n [ 690 4349]]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"ft_model = FastText(sentences=sent, vector_size=100, window=3, min_count=1, sg=1, workers=4)\n\ndf['average_word_vector_ft'] = df['processed_text'].apply(lambda x: get_average_word_vector(x.split(), ft_model))\n\nX = df['average_word_vector_ft'].dropna().tolist()\ny = df['sentiment'].dropna().tolist()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nft_classifier = LogisticRegression()\nft_classifier.fit(X_train, y_train)\n\nft_y_pred = ft_classifier.predict(X_test)\n\nft_accuracy = accuracy_score(y_test, ft_y_pred)\nprint(f\"FastText Accuracy: {ft_accuracy:.4f}\")\nprint(\"Classification Report:\")\nprint(classification_report(y_test, ft_y_pred))\nprint(\"Confusion Matrix:\")\nprint(confusion_matrix(y_test, ft_y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T11:24:28.972579Z","iopub.execute_input":"2025-09-06T11:24:28.972970Z","iopub.status.idle":"2025-09-06T11:28:05.570898Z","shell.execute_reply.started":"2025-09-06T11:24:28.972946Z","shell.execute_reply":"2025-09-06T11:28:05.570010Z"}},"outputs":[{"name":"stdout","text":"FastText Accuracy: 0.8643\nClassification Report:\n              precision    recall  f1-score   support\n\n    negative       0.87      0.86      0.86      4961\n    positive       0.86      0.87      0.87      5039\n\n    accuracy                           0.86     10000\n   macro avg       0.86      0.86      0.86     10000\nweighted avg       0.86      0.86      0.86     10000\n\nConfusion Matrix:\n[[4251  710]\n [ 647 4392]]\n","output_type":"stream"}],"execution_count":27}]}